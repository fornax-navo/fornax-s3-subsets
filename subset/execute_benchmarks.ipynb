{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from killscreen.utilities import roundstring\n",
    "\n",
    "# hacky; can remove if we decide to add an install script or put this in the repo root\n",
    "os.chdir(globals()['_dh'][0].parent)\n",
    "\n",
    "from subset.benchmark.bench_utils import (\n",
    "    check_existing_benchmarks,\n",
    "    dump_bandwidth_allowance_metrics,\n",
    "    dump_throwaway_results\n",
    ")\n",
    "from subset.benchmark.handlers import (\n",
    "    execute_test_case, interpret_benchmark_instructions, process_bench_stats\n",
    ")\n",
    "from subset.utilz.generic import summarize_stat\n",
    "from subset.utilz.mount_s3 import mount_bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "simple execution environment for dataset benchmarking. executes benchmarks defined in the benchmark_settings module.\n",
    "\n",
    "important notes:\n",
    "* the `fsspec`-based \"s3\" and \"s3_section\" loaders will only function on the barentsen/cloud-support astropy branch.\n",
    "* other loaders will only function if `goofys` is executable from the user's path.\n",
    "* attempts to access private buckets, via either `goofys` or `fsspec`, will use credentials stored in ~/.aws/credentials.\n",
    "* bandwidth throttling will only work if `wondershaper` is executable from the user's path, the user is a sudoer, and the user has no `sudo` password (like \"ubuntu\" in stock AWS EC2 Ubuntu images).\n",
    "* this currently assumes that the network interface of interest is named \"ens5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SETTINGS = {\n",
    "    # directory goofys will use as a mount point for buckets\n",
    "    \"mountpoint\": \"/mnt/s3/\",\n",
    "    # max files: tests will use the top n_files elements of the TEST_FILES\n",
    "    # attribute of each benchmark module (unless less than n_files are given\n",
    "    # in TEST_FILES)\n",
    "    \"n_files\": 25,\n",
    "    # do we actually want to look at the cuts? probably not in big bulk\n",
    "    # benchmarks, but can be useful for diagnostics or if you want a\n",
    "    # screensaver or whatever.\n",
    "    \"return_cuts\": False,\n",
    "    # rng seed for consistent execution w/out having to explicitly define\n",
    "    # a very long list of rectangles\n",
    "    \"seed\": 123456,\n",
    "    # these values are given in kilobits per second. None means unthrottled.\n",
    "    # if you don't pass this key, there won't be any throttling in any test.\n",
    "    # \"bandwidth\": (None, 100 * 1000)\n",
    "}\n",
    "# these correspond to the names of submodules of the benchmark_settings module\n",
    "BENCHMARK_NAMES = (\n",
    "    \"hst\", \"panstarrs\", \"galex_rice\", \"jwst_crf\", \"tesscut\", \"galex_gzip\",\n",
    "    \"hst_big\", \"spitzer_irac\", \"spitzer_cosmos_irac\"\n",
    ")\n",
    "# if there is an existing result file corresponding to a particular\n",
    "# test case, shall we run it again (w/incrementing suffixes attached to\n",
    "# outputs?)\n",
    "DUPLICATE_BENCHMARKS = False\n",
    "# where shall we write benchmark results?\n",
    "METRIC_DIRECTORY = \"subset/benchmark/bench_results\"\n",
    "Path(METRIC_DIRECTORY).mkdir(parents=True, exist_ok=True)\n",
    "# how many throwaway tests should we run every time we switch the specific\n",
    "# set of cuts we're using? this is intended to juice S3 serverside caching\n",
    "# so that earlier-in-order cases aren't 'penalized' without us having to\n",
    "# either make a separate copy of all S3 objects for every test case, select\n",
    "# random objects from a larger corpus, or wait a long time (60s - 15m,\n",
    "# ish) between each test case. this is spooky, because it's a black box --\n",
    "# we have no way to seriously interrogate how this works. It can affect run\n",
    "# times by a factor of 2-3 in many cases, though.\n",
    "N_THROWAWAYS = 3\n",
    "# \"benchmarks\" contains instructions for each test case\n",
    "benchmarks = {\n",
    "    name: interpret_benchmark_instructions(name, SETTINGS)\n",
    "    for name in BENCHMARK_NAMES\n",
    "}\n",
    "# partially-evaluated S3 mount function, for convenience\n",
    "remount = partial(mount_bucket, SETTINGS['mountpoint'], remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "execute all benchmarks in a loop and save results. you can mess with this cell\n",
    "to pretty straightforwardly look at only certain categories of cases,\n",
    "suppress results, etc.\n",
    "\"\"\"\n",
    "logs = {}\n",
    "for benchmark_name, benchmark in benchmarks.items():\n",
    "    previous = {}\n",
    "    for case in benchmark:\n",
    "        skip, suffix = check_existing_benchmarks(\n",
    "            case['title'], DUPLICATE_BENCHMARKS, METRIC_DIRECTORY\n",
    "        )\n",
    "        if skip is True:\n",
    "            continue\n",
    "        cuts, stat, log, throwaways = execute_test_case(\n",
    "            case, previous, remount, N_THROWAWAYS\n",
    "        )\n",
    "        print(roundstring(summarize_stat(stat)) + \"\\n\")\n",
    "        logs[f\"{case['title']}\"] = log\n",
    "        process_bench_stats(log, case, benchmark_name).to_csv(\n",
    "            Path(METRIC_DIRECTORY, f\"{case['title']}_benchmark_{suffix}.csv\"),\n",
    "            index=None\n",
    "        )\n",
    "        dump_bandwidth_allowance_metrics(case['title'], suffix, METRIC_DIRECTORY)\n",
    "        dump_throwaway_results(throwaways, case['title'], suffix, METRIC_DIRECTORY)\n",
    "        previous = case\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
